#!/bin/sh
##############################################################################
#
# Output a datatable in JSON. 
# https://developers.google.com/chart/interactive/docs/reference#DataTable_toJSON
#
# Our intent is to compute an activity metric across all nodes of the
# cluster. I want to know what my machines are doing.
# The current method counts workunits in processing, on a daily basis.
# See SQL_SELECT_PIVOT_PROJECT below. 
# Pretty good for last-lasting workunits that
# need over 1 day to complete. But this overestimates actual activity for
# fast-completing workunits. They artificially inflate the activity metric.
#
# Something about task.current_cpu_time on a daily basis? 
# Or do the counts hourly, them sum up by day?
##############################################################################

# input parameter
readonly LOOKBACK_DAYS=${1:-0} # default value

readonly DATABASE=boinc_cluster_state.db
#readonly DATABASE=t/_test.db # for testing
#readonly DATABASE=t.db

readonly NULL_ROW='{ "c": [] }'

readonly COLUMN_DEFS='
	{
		"id": "created",
		"label": "Day",
		"type": "datetime"
	},
	{
		"id": "aster",
		"label": "Asteroids",
		"type": "number"
	},
	{
		"id": "einst",
		"label": "Einstein",
		"type": "number"
	},
	{
		"id": "roset",
		"label": "Rosetta",
		"type": "number"
	},
	{
		"id": "univ",
		"label": "Universe",
		"type": "number"
	},
	{
		"id": "wcg",
		"label": "World Community Grid",
		"type": "number"
	},
	{
		"id": "yoyo",
		"label": "yoyo",
		"type": "number"
	}'

# it's static: cannot adapt to new apps, so:
# we group by project, not app
# project names are fixed 
# Pro: it's super fast
readonly SQL_SELECT_PIVOT_PROJECT="
    SELECT 
        strftime('%Y', captured, 'localtime') as created_y,
        strftime('%m', captured, 'localtime') as created_m,
        strftime('%d', captured, 'localtime') as created_d,
        -- order does not matter below
        COUNT(DISTINCT CASE WHEN project_name = 'yoyo@home'            THEN result.name END) AS yoyo,
        COUNT(DISTINCT CASE WHEN project_name = 'World Community Grid' THEN result.name END) AS wcg,
        COUNT(DISTINCT CASE WHEN project_name = 'Asteroids@home'       THEN result.name END) AS astr,
        COUNT(DISTINCT CASE WHEN project_name = 'Rosetta@home'         THEN result.name END) AS rose,
        COUNT(DISTINCT CASE WHEN project_name = 'Universe@Home'        THEN result.name END) AS univ,
        COUNT(DISTINCT CASE WHEN project_name = 'Einstein@Home'        THEN result.name END) AS einst
    FROM 
        result 
        JOIN task USING (task_id)
        JOIN task_state ON active_task_state = task_state.code
    WHERE 
        datetime(captured) >= datetime('now', '-$LOOKBACK_DAYS day')
        AND task_state.name = 'PROCESS_EXECUTING'
    GROUP BY 1, 2, 3
"

readonly SQL_SELECT_JSON="
    SELECT 
        json_object('c', 
            json_array( 
				-- dumbass JSON dates use 0-based months
                json_object('v', 'Date(' || created_y || ',' || (created_m - 1) || ',' || created_d || ')'),
                -- order must match COLUMN_DEFS above
                json_object('v', astr),
                json_object('v', einst),
                json_object('v', rose),
                json_object('v', univ),
                json_object('v', wcg),
                json_object('v', yoyo)
                ))
    FROM ( $SQL_SELECT_PIVOT_PROJECT )
"

##############################################################################
# main

rows=$( sqlite3 -list -noheader -newline "," "$DATABASE" "$SQL_SELECT_JSON" )

# output entire document
cat <<_JSON_ 
{
	"cols": [ $COLUMN_DEFS ],
	"rows": [ $rows $NULL_ROW ]
}
_JSON_
